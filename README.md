# Distributed ML Pipeline

A production-ready distributed machine learning pipeline built with Python, Celery, Redis, and MLflow.

## ğŸš€ Features

- **Distributed Task Queue**: Celery workers for parallel ML tasks
- **MLflow Integration**: Experiment tracking and model registry
- **Feature Store**: Offline and online feature serving
- **Model Serving**: REST API with FastAPI
- **Data Pipeline**: Apache Airflow DAGs for ETL
- **Monitoring**: Prometheus metrics and Grafana dashboards

## ğŸ“¦ Installation

```bash
git clone https://github.com/Brainfeed-1996/distributed-ml-pipeline-py.git
cd distributed-ml-pipeline-py

# Install dependencies
pip install -r requirements.txt

# Start services
docker-compose up -d
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Distributed ML Pipeline                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Airflow   â”‚â”€â”€â”€â–¶â”‚  Celery      â”‚â”€â”€â”€â–¶â”‚   MLflow          â”‚  â”‚
â”‚  â”‚   DAGs      â”‚    â”‚  Workers      â”‚    â”‚   Server          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                   â”‚                    â”‚               â”‚
â”‚         â–¼                   â–¼                    â–¼               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Redis Broker                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                      â”‚
â”‚                           â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                   Feature Store                          â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚   Offline   â”‚    â”‚   Online     â”‚    â”‚  Redis     â”‚  â”‚   â”‚
â”‚  â”‚  â”‚   (S3)      â”‚    â”‚   (API)      â”‚    â”‚  Cache     â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                      â”‚
â”‚                           â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                   FastAPI Server                        â”‚   â”‚
â”‚  â”‚  - Model inference endpoint                             â”‚   â”‚
â”‚  â”‚  - Feature serving                                      â”‚   â”‚
â”‚  â”‚  - Health checks                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
distributed-ml-pipeline-py/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipelines/           # Celery tasks
â”‚   â”‚   â”œâ”€â”€ training.py      # Model training
â”‚   â”‚   â”œâ”€â”€ preprocessing.py # Data preprocessing
â”‚   â”‚   â””â”€â”€ evaluation.py    # Model evaluation
â”‚   â”œâ”€â”€ features/           # Feature engineering
â”‚   â”‚   â”œâ”€â”€ definitions.py   # Feature definitions
â”‚   â”‚   â””â”€â”€ store.py         # Feature store client
â”‚   â”œâ”€â”€ models/              # Model registry
â”‚   â”‚   â”œâ”€â”€ training.py       # Training logic
â”‚   â”‚   â””â”€â”€ inference.py     # Inference utilities
â”‚   â””â”€â”€ api/                  # FastAPI endpoints
â”œâ”€â”€ dags/                    # Airflow DAGs
â”œâ”€â”€ notebooks/               # Jupyter notebooks
â”œâ”€â”€ tests/                   # Unit tests
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## ğŸ”§ Usage

### Start the Pipeline

```bash
# Start Redis and MLflow
docker-compose up -d

# Start Celery workers
celery -A src.pipelines worker --loglevel=info

# Start FastAPI server
uvicorn src.api.main:app --reload
```

### Run Training Pipeline

```python
from src.pipelines.training import train_model

# Trigger distributed training
result = train_model.delay(
    model_type="xgboost",
    hyperparameters={"n_estimators": 100, "max_depth": 6},
    experiment_name="production-v1"
)
```

### Track Experiments

```python
import mlflow
import mlflow.xgboost

with mlflow.start_run(experiment_id="production-v1"):
    mlflow.log_params(hyperparameters)
    mlflow.log_metrics(metrics)
    mlflow.xgboost.log_model(model, "model")
```

## ğŸ“Š Features

### Feature Store

```python
from src.features.store import FeatureStore

# Get features for inference
features = FeatureStore.get_online(
    entity_ids=["user_123", "user_456"],
    feature_set="user_features"
)
```

### Model Serving

```bash
# Make predictions
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"features": [1.2, 3.4, 5.6]}'
```

## ğŸ§ª Testing

```bash
# Run unit tests
pytest tests/ -v

# Run integration tests
pytest tests/integration/ -v
```

## ğŸ“ License

MIT License
